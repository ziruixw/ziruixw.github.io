<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Zirui Wang | Apple AI/ML</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href='http://fonts.googleapis.com/css?family=Arizonia' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <!-- Custom styles for this template -->
    <link href="css/index.css" rel="stylesheet">

  </head>

  <body id="page-top">

    <!-- Navigation -->
     <nav class="navbar navbar-expand-lg navbar-light bg-dark fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="#page-top"></a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#about">About Me</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#publication">Publication</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <header class="text-black">
      <div class="container text-center">
        <div class = "row">
          <img src="photo.jpg" class="profile" alt="profile picture">
          <div class = "col text-left" id = "profile-text">
            <h1>Zirui Wang</h1>
            <h3>王子瑞</h3>
            <p>Apple AI/ML</p>
            <p>Email:  ziruiw [at] apple (dot) com</p>
            <p><a href="https://scholar.google.com/citations?user=GgD-B68AAAAJ" target="_blank">Google Scholar</a></p>
            <p><a href="https://www.linkedin.com/in/zirui-wang-33217b41/" target="_blank">LinkedIn</a> / <a href="https://twitter.com/MrZiruiWang" target="_blank">Twitter</a></p>
          </div>
        </div>
      </div>
    </header>

    <section id="about">
      <div class="container">
        <div class="row">
          <div class="col-lg-10 mx-auto">
            <p>I currently lead the post-training effort for Apple Foundation Models. Before that, I was a Research Scientist at Google Brain. I work on language modeling, multimodal models and generative models.</p>

            <p>I received my PhD at <a href="https://www.lti.cs.cmu.edu/" target="_blank">Language Technologies Institute</a> in <a href="https://www.cmu.edu/index.html" target="_blank">Carnegie Mellon University</a>, advised by Professor <a href="https://www.cs.cmu.edu/~jgc/" target="_blank">Jaime Carbonell</a>. Sadly, Jaime passed away in 2020 and I had been working with Professor <a href="https://www.cs.cmu.edu/~ytsvetko/" target="_blank">Yulia Tsvetkov</a> and Professor <a href="https://strubell.github.io"target="_blank">Emma Strubell</a> since then. Jaime will always be my advisor and deeply missed. Prior to my graduate studies, I obtained my Bachelar in Computer Science at Carnegie Mellon University.</p>
          </div>
        </div>
      </div>
    </section>

    <section id="publication">
      <div class="container">
        <div class="row">
          <div class="col-lg-10 mx-auto">
            <h2>Publications</h2>
            <p>* indicates co-first author.</p>
            <p>
              <font color="black" class="publication-title">
                <em>CoCa: Contrastive Captioners are Image-Text Foundation Models.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                Jiahui Yu*, <b>Zirui Wang*</b>, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini, Yonghui Wu.
                <br> 
                TMLR 2022.
                [<a href="https://arxiv.org/abs/2205.01917">arxiv</a>]
                [<a href="https://research.google/blog/image-text-pre-training-with-contrastive-captioners/">Google AI Blog</a>]
              </font>
            </p>
            <p>
              <font color="black" class="publication-title">
                <em>SimVLM: Simple Visual Language Model Pretraining with Weak Supervision.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                <b>Zirui Wang</b>, Jiahui Yu, Adams Wei Yu, Zihang Dai, Yulia Tsvetkov, Yuan Cao.
                <br> 
                ICLR 2022.
                [<a href="https://arxiv.org/abs/2108.10904">arxiv</a>]
                [<a href="https://research.google/blog/simvlm-simple-visual-language-model-pre-training-with-weak-supervision/">Google AI Blog</a>]
              </font>
            </p>
            <p>
              <font color="black" class="publication-title">
                <em>Ferret: Refer and Ground Anything Anywhere at Any Granularity.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                Haoxuan You, Haotian Zhang, Zhe Gan, Xianzhi Du, Bowen Zhang, <b>Zirui Wang</b>, Liangliang Cao, Shih-Fu Chang, Yinfei Yang.
                <br> 
                ICLR 2024.
                [<a href="https://arxiv.org/abs/2310.07704">arxiv</a>]
                [<a href="https://github.com/apple/ml-ferret">code</a>]
              </font>
            </p>
            <p>
              <font color="black" class="publication-title">
                <em>MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                Brandon McKinzie, Zhe Gan, Jean-Philippe Fauconnier, Sam Dodge, Bowen Zhang, Philipp Dufter, Dhruti Shah, Xianzhi Du, Futang Peng, Floris Weers, Anton Belyi, Haotian Zhang, Karanjeet Singh, Doug Kang, Ankur Jain, Hongyu Hè, Max Schwarzer, Tom Gunter, Xiang Kong, Aonan Zhang, Jianyu Wang, Chong Wang, Nan Du, Tao Lei, Sam Wiseman, Guoli Yin, Mark Lee, <b>Zirui Wang</b>, Ruoming Pang, Peter Grasch, Alexander Toshev, Yinfei Yang.
                <br> 
                Arxiv 2024.
                [<a href="https://arxiv.org/abs/2403.09611">arxiv</a>]
              </font>
            </p>
            <p>
              <font color="black" class="publication-title">
                <em>Revisiting MoE and Dense Speed-Accuracy Comparisons for LLM Training.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                Xianzhi Du, Tom Gunter, Xiang Kong, Mark Lee, <b>Zirui Wang</b>, Aonan Zhang, Nan Du, Ruoming Pang.
                <br> 
                Arxiv 2024.
                [<a href="https://arxiv.org/abs/2405.15052">arxiv</a>]
              </font>
            </p>
            <p>
              <font color="black" class="publication-title">
                <em>REVEAL: Retrieval-Augmented Visual-Language Pre-Training With Multi-Source Multimodal Knowledge Memory.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                Ziniu Hu, Ahmet Iscen, Chen Sun, <b>Zirui Wang</b>, Kai-Wei Chang, Yizhou Sun, Cordelia Schmid, David A. Ross, Alireza Fathi.
                <br> 
                CVPR 2023.
                [<a href="https://arxiv.org/abs/2212.05221">arxiv</a>]
                [<a href="https://research.google/blog/retrieval-augmented-visual-language-pre-training/">Google AI Blog</a>]
              </font>
            </p>
            <p>
              <font color="black" class="publication-title">
                <em>Guiding Image Captioning Models Toward More Specific Captions.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                Simon Kornblith, Lala Li, <b>Zirui Wang</b>, Thao Nguyen.
                <br> 
                CVPR 2023.
                [<a href="https://arxiv.org/abs/2307.16686">arxiv</a>]
              </font>
            </p>
            <p>
              <font color="black" class="publication-title">
                <em>Scaling Autoregressive Models for Content-Rich Text-to-Image Generation.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, <b>Zirui Wang</b>, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu Karagol Ayan, Ben Hutchinson, Wei Han, Zarana Parekh, Xin Li, Han Zhang, Jason Baldridge, Yonghui Wu.
                <br> 
                TMLR 2022.
                [<a href="https://arxiv.org/abs/2206.10789">arxiv</a>]
                [<a href="https://sites.research.google/parti/">Parti Website</a>]
              </font>
            </p>
            <p>
              <font color="black" class="publication-title">
                <em>VideoCoCa: Video-Text Modeling with Zero-Shot Transfer from Contrastive Captioners.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                Shen Yan, Tao Zhu, <b>Zirui Wang</b>, Yuan Cao, Mi Zhang, Soham Ghosh, Yonghui Wu, Jiahui Yu.
                <br> 
                Arxiv 2022.
                [<a href="https://arxiv.org/abs/2212.04979">arxiv</a>]
              </font>
            </p>
            <p>
              <font color="black" class="publication-title">
                <em>Exploiting Category Names for Few-Shot Classification with Vision-Language Models.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                Taihong Xiao, <b>Zirui Wang</b>, Liangliang Cao, Jiahui Yu, Shengyang Dai, Ming-Hsuan Yang.
                <br> 
                Arxiv 2022.
                [<a href="https://arxiv.org/abs/2211.16594">arxiv</a>]
              </font>
            </p>
            <p>
              <font color="black" class="publication-title">
                <em>Towards Zero-Label Language Learning.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                <b>Zirui Wang</b>, Adams Wei Yu, Orhan Firat, Yuan Cao.
                <br> 
                Arxiv 2021.
                [<a href="https://arxiv.org/abs/2109.09193">arxiv</a>]
              </font>
            </p>
            <p>
              <font color="black" class="publication-title">
                <em>Gradient Vaccine: Investigating and Improving Multi-task Optimization in Massively Multilingual Models.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                <b>Zirui Wang</b>, Yulia Tsvetkov, Orhan Firat, Yuan Cao.
                <br> 
                ICLR 2021 (Spotlight).
                [<a href="https://arxiv.org/abs/2010.05874">arxiv</a>]
              </font>
            </p>

            <p>
              <font color="black" class="publication-title">
                <em>On Negative Interference in Multilingual Models: Findings and A Meta-Learning Treatment.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                <b>Zirui Wang</b>, Zachary C Lipton, Yulia Tsvetkov.
                <br> 
                EMNLP 2020.
                [<a href="https://arxiv.org/abs/2010.03017">arxiv</a>]
                [<a href="https://github.com/iedwardwangi/MetaAdapter">code</a>]
              </font>
            </p>
            <p>
              <font color="black" class="publication-title">
                <em>Efficient Meta Lifelong-Learning with Limited Memory.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                <b>Zirui Wang*</b>, Sanket Vaibhav Mehta*, Barnabás Póczos, Jaime Carbonell.
                <br> 
                EMNLP 2020.
                [<a href="https://arxiv.org/abs/2010.02500">arxiv</a>]
                [<a href="https://github.com/sanketvmehta/efficient-meta-lifelong-learning">code</a>]
              </font>
            </p>
            <p>
              <font color="black" class="publication-title">
                <em>Cross-lingual Alignment vs Joint Training: A Comparative Study and A Simple Unified Framework.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                <b>Zirui Wang*</b>, Jiateng Xie*, Ruochen Xu, Yiming Yang, Graham Neubig, Jaime Carbonell.
                <br> 
                ICLR 2020.
                [<a href="https://arxiv.org/abs/1910.04708">arxiv</a>]
                [<a href="https://github.com/thespectrewithin/joint_align">code</a>]
                [<a href="https://iclr.cc/virtual_2020/poster_S1l-C0NtwS.html">presentation</a>]
              </font>
            </p>
            <p>
              <font color="black" class="publication-title">
                <em>Characterizing and Avoiding Negative Transfer.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                <b>Zirui Wang</b>, Zihang Dai, Barnabás Póczos, Jaime Carbonell.
                <br> 
                CVPR 2019.
                [<a href="http://arxiv.org/abs/1811.09751">arxiv</a>]
              </font>
            </p>
            <p>
              <font color="black" class="publication-title">
                <em>Towards more Reliable Transfer Learning.</em>
              </font>
              <br>
          
              <font class="publication-sub">
                <b>Zirui Wang</b>, Jaime Carbonell.
                <br> 
                ECML-PKDD 2018.
                [<a href="https://arxiv.org/abs/1807.02235">arxiv</a>]
                [<a href="doc/towards_more_reliable_transfer_learning_supplimentary.pdf">sup</a>]
                [<a href="doc/towards_more_reliable_transfer_learning_present.pdf">slides</a>]
              </font>
            </p>
          </div>
        </div>
      </div>
    </section>

    <!-- Footer -->
    <footer class="py-5 bg-dark">
      <div class="container">
        <!-- <p class="m-0 text-center text-white"></p> -->
        <div class = "row justify-content-md-center">
          <a href="https://scholar.google.com/citations?user=GgD-B68AAAAJ" class="fa fa-graduation-cap" target="_blank"></a>
          <a href="https://twitter.com/MrZiruiWang" class="fa fa-twitter" target="_blank"></a>
          <a href="https://www.linkedin.com/in/zirui-wang-33217b41/" class="fa fa-linkedin" target="_blank"></a>          
          <a href="mailto:ziruiw@apple.com" class="fa fa-envelope" target="_blank"></a>
        </div>
      <!-- /.container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Custom JavaScript for this theme -->
    <script src="js/scrolling-nav.js"></script>

  </body>

</html>